{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b19c014e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install transformers pillow torch torchvision tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0310305",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\h5py\\__init__.py:36: UserWarning: h5py is running against HDF5 1.14.6 when it was built against 1.14.5, this may cause problems\n",
      "  _warn((\"h5py is running against HDF5 {0} when it was built against {1}, \"\n"
     ]
    }
   ],
   "source": [
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "from PIL import Image\n",
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "# Load BLIP model\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d389da4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = r\"C:\\Users\\Lenovo\\Downloads\\archive (19)\\raw-img\"     \n",
    "output_file = \"animal10_captions.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e5ba76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import json\n",
    "# from PIL import Image\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# captions = []\n",
    "\n",
    "# MAX_IMAGES = 100   # per animal class\n",
    "\n",
    "# for folder in os.listdir(dataset_path):\n",
    "#     folder_path = os.path.join(dataset_path, folder)\n",
    "\n",
    "#     if not os.path.isdir(folder_path):\n",
    "#         continue\n",
    "\n",
    "#     print(\"Processing:\", folder)\n",
    "\n",
    "#     # Get all images in folder\n",
    "#     img_list = os.listdir(folder_path)\n",
    "\n",
    "#     # Keep only 500 images\n",
    "#     img_list = img_list[:MAX_IMAGES]\n",
    "\n",
    "#     for img_name in tqdm(img_list, desc=folder):\n",
    "#         img_path = os.path.join(folder_path, img_name)\n",
    "\n",
    "#         try:\n",
    "#             image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "#             # Generate 3 captions per image\n",
    "#             image_captions = []\n",
    "#             for i in range(3):\n",
    "#                 inputs = processor(image, return_tensors=\"pt\")\n",
    "                \n",
    "#                 caption_ids = model.generate(\n",
    "#                     **inputs,\n",
    "#                     num_beams=1,       # faster + gives variation\n",
    "#                     temperature=1.2    # more creativity\n",
    "#                 )\n",
    "\n",
    "#                 caption = processor.decode(\n",
    "#                     caption_ids[0], \n",
    "#                     skip_special_tokens=True\n",
    "#                 )\n",
    "\n",
    "#                 image_captions.append(caption)\n",
    "\n",
    "#             captions.append({\n",
    "#                 \"image\": f\"{folder}/{img_name}\",\n",
    "#                 \"captions\": image_captions\n",
    "#             })\n",
    "\n",
    "#         except Exception as e:\n",
    "#             print(\"Error on:\", img_path, \":\", str(e))\n",
    "\n",
    "# # Save\n",
    "# with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(captions, f, indent=4)\n",
    "\n",
    "# print(\"âœ” Captions Saved Successfully:\", output_file)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c1c2f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 1000\n",
      "Sample: {'image': 'cane/OIF-e2bexWrojgtQnAPPcUfOWQ.jpeg', 'captions': ['a small dog sitting on a couch', 'a small dog sitting on a couch', 'a small dog sitting on a couch']}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load captions\n",
    "with open(\"animal10_captions.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(\"Total images:\", len(data))\n",
    "print(\"Sample:\", data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "548cbed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (5): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (6): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (7): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import models\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load ResNet50\n",
    "resnet = models.resnet50(pretrained=True)\n",
    "resnet = torch.nn.Sequential(*list(resnet.children())[:-1])  # remove last FC layer\n",
    "resnet.to(device)\n",
    "resnet.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd9aa7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10e192b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet50 loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load pretrained ResNet50\n",
    "resnet = models.resnet50(pretrained=True)\n",
    "resnet = torch.nn.Sequential(*list(resnet.children())[:-1])\n",
    "\n",
    "resnet.to(device)\n",
    "resnet.eval()\n",
    "\n",
    "print(\"ResNet50 loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b36942cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 1000\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"animal10_captions.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(\"Total images:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8cec70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting image features: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [03:05<00:00,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ” Feature extraction finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "dataset_path = \"C:/Users/Lenovo/Downloads/archive (19)/raw-img\"\n",
    "features = {}\n",
    "\n",
    "for item in tqdm(data, desc=\"Extracting image features\"):\n",
    "    img_path = os.path.join(dataset_path, item['image'])\n",
    "    \n",
    "    try:\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        img_tensor = transform(image).unsqueeze(0).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            feat = resnet(img_tensor).squeeze().cpu().numpy()\n",
    "        \n",
    "        features[item['image']] = feat\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", img_path, \"|\", str(e))\n",
    "\n",
    "# Save\n",
    "np.save(\"image_features.npy\", features)\n",
    "print(\"Feature extraction finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d88e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ” Vocabulary size: 448\n",
      "âœ” Max caption length: 21\n",
      "âœ” Caption sequences processed and saved.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "with open(\"animal10_captions.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "all_captions = []\n",
    "\n",
    "# Clean and collect captions\n",
    "for item in data:\n",
    "    for cap in item[\"captions\"]:\n",
    "        cap = cap.lower().strip()\n",
    "        cap = re.sub(r\"[^a-zA-Z0-9 ]\", \"\", cap)  # remove symbols\n",
    "        all_captions.append(cap)\n",
    "\n",
    "word_counts = Counter()\n",
    "for cap in all_captions:\n",
    "    word_counts.update(cap.split())\n",
    "\n",
    "min_freq = 2\n",
    "vocab_words = [w for w, c in word_counts.items() if c >= min_freq]\n",
    "\n",
    "# Add special tokens\n",
    "vocab_words = [\"<pad>\", \"<start>\", \"<end>\", \"<unk>\"] + vocab_words\n",
    "\n",
    "word2idx = {w: idx for idx, w in enumerate(vocab_words)}\n",
    "idx2word = {idx: w for w, idx in word2idx.items()}\n",
    "\n",
    "print(\"Vocabulary size:\", len(vocab_words))\n",
    "\n",
    "# save vocabulary\n",
    "with open(\"vocab.json\", \"w\") as f:\n",
    "    json.dump({\"word2idx\": word2idx, \"idx2word\": idx2word}, f)\n",
    "\n",
    "# Convert captions to sequences\n",
    "def caption_to_seq(caption):\n",
    "    caption = caption.lower().strip()\n",
    "    caption = re.sub(r\"[^a-zA-Z0-9 ]\", \"\", caption)\n",
    "    tokens = caption.split()\n",
    "\n",
    "    seq = [word2idx[\"<start>\"]]\n",
    "\n",
    "    for t in tokens:\n",
    "        if t in word2idx:\n",
    "            seq.append(word2idx[t])\n",
    "        else:\n",
    "            seq.append(word2idx[\"<unk>\"])\n",
    "\n",
    "    seq.append(word2idx[\"<end>\"])\n",
    "    return seq\n",
    "\n",
    "processed = []\n",
    "max_len = 0\n",
    "\n",
    "for item in data:\n",
    "    img = item[\"image\"]\n",
    "    caps = []\n",
    "\n",
    "    for cap in item[\"captions\"]:\n",
    "        seq = caption_to_seq(cap)\n",
    "        caps.append(seq)\n",
    "        max_len = max(max_len, len(seq))\n",
    "\n",
    "    processed.append({\n",
    "        \"image\": img,\n",
    "        \"caption_seqs\": caps\n",
    "    })\n",
    "\n",
    "print(\"Max caption length:\", max_len)\n",
    "\n",
    "def pad_sequence(seq, max_len):\n",
    "    return seq + [word2idx[\"<pad>\"]] * (max_len - len(seq))\n",
    "\n",
    "for item in processed:\n",
    "    item[\"caption_seqs\"] = [pad_sequence(s, max_len) for s in item[\"caption_seqs\"]]\n",
    "\n",
    "# Save processed captions\n",
    "with open(\"processed_captions.json\", \"w\") as f:\n",
    "    json.dump(processed, f)\n",
    "\n",
    "print(\"Caption sequences processed and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae387e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ” Dataset and DataLoader created successfully!\n",
      "Total samples: 1000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "\n",
    "features = np.load(\"image_features.npy\", allow_pickle=True).item()\n",
    "\n",
    "with open(\"processed_captions.json\", \"r\") as f:\n",
    "    processed = json.load(f)\n",
    "\n",
    "with open(\"vocab.json\", \"r\") as f:\n",
    "    vocab = json.load(f)\n",
    "    word2idx = vocab[\"word2idx\"]\n",
    "    idx2word = {int(k): v for k, v in vocab[\"idx2word\"].items()}\n",
    "\n",
    "vocab_size = len(word2idx)\n",
    "\n",
    "class AnimalCaptionDataset(Dataset):\n",
    "    def __init__(self, processed, features):\n",
    "        self.data = processed\n",
    "        self.features = features\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "\n",
    "        img_name = item[\"image\"]\n",
    "        img_feat = torch.tensor(self.features[img_name], dtype=torch.float32)\n",
    "\n",
    "        # pick 1 caption randomly\n",
    "        captions = item[\"caption_seqs\"]\n",
    "        cap = captions[np.random.randint(len(captions))]\n",
    "        cap = torch.tensor(cap, dtype=torch.long)\n",
    "\n",
    "        return img_feat, cap\n",
    "\n",
    "\n",
    "dataset = AnimalCaptionDataset(processed, features)\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "print(\"Dataset and DataLoader created successfully!\")\n",
    "print(\"Total samples:\", len(dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2acf3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CaptionModel(nn.Module):\n",
    "    def __init__(self, feature_dim, embed_dim, hidden_dim, vocab_size, num_layers=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.feature_embed = nn.Linear(feature_dim, embed_dim)\n",
    "        self.word_embed = nn.Embedding(vocab_size, embed_dim)\n",
    "\n",
    "        # LSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embed_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        # Output layer\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, img_feat, captions):\n",
    "        \"\"\"\n",
    "        img_feat: (batch, 2048)\n",
    "        captions: (batch, seq_len)\n",
    "        \"\"\"\n",
    "\n",
    "        img_embed = self.feature_embed(img_feat)\n",
    "        img_embed = img_embed.unsqueeze(1)\n",
    "\n",
    "        # Embed caption tokens\n",
    "        cap_embed = self.word_embed(captions)\n",
    "\n",
    "        inp = torch.cat([img_embed, cap_embed], dim=1)\n",
    "\n",
    "        # LSTM forward\n",
    "        h, _ = self.lstm(inp)\n",
    "\n",
    "        # Predict next word\n",
    "        out = self.fc(h)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06769ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss = 84.3754\n",
      "Epoch 2/10, Loss = 23.3270\n",
      "Epoch 3/10, Loss = 10.4257\n",
      "Epoch 4/10, Loss = 5.3669\n",
      "Epoch 5/10, Loss = 2.9405\n",
      "Epoch 6/10, Loss = 1.5607\n",
      "Epoch 7/10, Loss = 0.7739\n",
      "Epoch 8/10, Loss = 0.4411\n",
      "Epoch 9/10, Loss = 0.2830\n",
      "Epoch 10/10, Loss = 0.2165\n",
      "âœ” Training Completed!\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "feature_dim = 2048\n",
    "embed_dim = 256\n",
    "hidden_dim = 512\n",
    "\n",
    "model = CaptionModel(feature_dim, embed_dim, hidden_dim, vocab_size).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=word2idx[\"<pad>\"])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "\n",
    "    for img_feat, caps in dataloader:\n",
    "        img_feat = img_feat.to(device)\n",
    "        caps = caps.to(device)\n",
    "\n",
    "        targets = caps\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(img_feat, caps)\n",
    "\n",
    "        # remove image token output -> align shapes\n",
    "        outputs = outputs[:, 1:, :]\n",
    "\n",
    "        loss = criterion(outputs.reshape(-1, vocab_size), targets.reshape(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss = {total_loss:.4f}\")\n",
    "\n",
    "print(\"Training Completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2058f320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as caption_model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"caption_model.pth\")\n",
    "print(\"Model saved as caption_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89053c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def evaluate_lstm(model, dataloader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_words = 0\n",
    "    correct = 0\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=word2idx[\"<pad>\"])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for img_feat, caps in dataloader:\n",
    "            img_feat = img_feat.to(device)\n",
    "            caps = caps.to(device)\n",
    "\n",
    "            outputs = model(img_feat, caps)\n",
    "            outputs = outputs[:, 1:, :]  # skip image token\n",
    "\n",
    "            loss = criterion(outputs.reshape(-1, vocab_size), caps.reshape(-1))\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # accuracy calculation\n",
    "            preds = outputs.argmax(dim=-1)\n",
    "            mask = (caps != word2idx[\"<pad>\"])\n",
    "\n",
    "            correct += ((preds == caps) & mask).sum().item()\n",
    "            total_words += mask.sum().item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    perplexity = math.exp(avg_loss)\n",
    "    accuracy = correct / total_words\n",
    "\n",
    "    return avg_loss, perplexity, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5254fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š LSTM Evaluation Results\n",
      "---------------------------------\n",
      "Loss       : 0.0059\n",
      "Perplexity : 1.0059\n",
      "Accuracy   : 100.00%\n"
     ]
    }
   ],
   "source": [
    "loss, ppl, acc = evaluate_lstm(model, dataloader)\n",
    "\n",
    "print(\"\\nðŸ“Š LSTM Evaluation Results\")\n",
    "print(f\"Loss       : {loss:.4f}\")\n",
    "print(f\"Perplexity : {ppl:.4f}\")\n",
    "print(f\"Accuracy   : {acc*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a60fa0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfcb3822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Animal classes: {'cane': 0, 'cavallo': 1, 'elefante': 2, 'farfalla': 3, 'gallina': 4, 'gatto': 5, 'mucca': 6, 'pecora': 7, 'ragno': 8, 'scoiattolo': 9}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "dataset_root = \"C:/Users/Lenovo/Downloads/archive (19)/raw-img\"\n",
    "\n",
    "# Map folder names to numeric labels\n",
    "classes = sorted(os.listdir(dataset_root))\n",
    "class_to_idx = {cls: i for i, cls in enumerate(classes)}\n",
    "\n",
    "print(\"Animal classes:\", class_to_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee924047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "scientific_to_label = {}  # auto-filled mapping\n",
    "\n",
    "class Animal10_CNN_Dataset(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "\n",
    "        self.samples = []\n",
    "        self.classes = sorted(os.listdir(root))\n",
    "\n",
    "        # assign numeric labels\n",
    "        for idx, cls in enumerate(self.classes):\n",
    "            scientific_to_label[cls] = idx\n",
    "            class_path = os.path.join(root, cls)\n",
    "\n",
    "            for img in os.listdir(class_path):\n",
    "                if img.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "                    self.samples.append((os.path.join(class_path, img), idx))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path, label = self.samples[index]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74dd9f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d615cc04",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf252156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ” 1000-image CNN dataset created at: C:/Users/Lenovo/cnn_1000\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "\n",
    "# source_root = r\"C:/Users/Lenovo/Downloads/archive (19)/raw-img\"\n",
    "# target_root = r\"C:/Users/Lenovo/cnn_1000\"\n",
    "# MAX_IMAGES = 100\n",
    "\n",
    "# os.makedirs(target_root, exist_ok=True)\n",
    "\n",
    "# for folder in os.listdir(source_root):\n",
    "#     class_path = os.path.join(source_root, folder)\n",
    "#     if not os.path.isdir(class_path):\n",
    "#         continue\n",
    "\n",
    "#     target_class_path = os.path.join(target_root, folder)\n",
    "#     os.makedirs(target_class_path, exist_ok=True)\n",
    "\n",
    "#     images = os.listdir(class_path)[:MAX_IMAGES]   # first 100\n",
    "\n",
    "#     for img in images:\n",
    "#         src = os.path.join(class_path, img)\n",
    "#         dst = os.path.join(target_class_path, img)\n",
    "#         shutil.copy(src, dst)\n",
    "\n",
    "# print(\"âœ” 1000-image CNN dataset created at:\", target_root)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f35695d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['cane', 'cavallo', 'elefante', 'farfalla', 'gallina', 'gatto', 'mucca', 'pecora', 'ragno', 'scoiattolo']\n",
      "Train size: 800\n",
      "Test size: 200\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# âœ… YOUR 1000-image CNN dataset\n",
    "dataset_root = r\"C:/Users/Lenovo/cnn_1000\"\n",
    "\n",
    "cnn_dataset = Animal10_CNN_Dataset(dataset_root, transform)\n",
    "\n",
    "train_size = int(0.8 * len(cnn_dataset))\n",
    "test_size = len(cnn_dataset) - train_size\n",
    "\n",
    "cnn_train, cnn_test = random_split(cnn_dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(cnn_train, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(cnn_test, batch_size=32, shuffle=False)\n",
    "\n",
    "print(\"Classes:\", cnn_dataset.classes)\n",
    "print(\"Train size:\", len(cnn_train))\n",
    "print(\"Test size:\", len(cnn_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8919f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Image transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18a71b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split completed!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset_root = r\"C:/Users/Lenovo/cnn_1000\"\n",
    "classes = os.listdir(dataset_root)\n",
    "\n",
    "# Create train/ and test/ folders\n",
    "train_dir = os.path.join(dataset_root, \"train\")\n",
    "test_dir = os.path.join(dataset_root, \"test\")\n",
    "\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "for cls in classes:\n",
    "    cls_path = os.path.join(dataset_root, cls)\n",
    "    if not os.path.isdir(cls_path):\n",
    "        continue\n",
    "    \n",
    "    images = os.listdir(cls_path)\n",
    "    images = [img for img in images if img.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
    "\n",
    "    train_imgs, test_imgs = train_test_split(images, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Make class folders in train/ and test/\n",
    "    os.makedirs(os.path.join(train_dir, cls), exist_ok=True)\n",
    "    os.makedirs(os.path.join(test_dir, cls), exist_ok=True)\n",
    "\n",
    "    # Move training images\n",
    "    for img in train_imgs:\n",
    "        shutil.copy(os.path.join(cls_path, img),\n",
    "                    os.path.join(train_dir, cls, img))\n",
    "\n",
    "    # Move testing images\n",
    "    for img in test_imgs:\n",
    "        shutil.copy(os.path.join(cls_path, img),\n",
    "                    os.path.join(test_dir, cls, img))\n",
    "\n",
    "print(\"Dataset split completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['cane', 'cavallo', 'elefante', 'farfalla', 'gallina', 'gatto', 'mucca', 'pecora', 'ragno', 'scoiattolo']\n",
      "Train size: 800\n",
      "Test size: 200\n"
     ]
    }
   ],
   "source": [
    "dataset_root = r\"C:/Users/Lenovo/cnn_1000\"\n",
    "\n",
    "train_data = datasets.ImageFolder(root=dataset_root + \"/train\", transform=transform)\n",
    "test_data  = datasets.ImageFolder(root=dataset_root + \"/test\", transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader  = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "print(\"Classes:\", train_data.classes)\n",
    "print(\"Train size:\", len(train_data))\n",
    "print(\"Test size:\", len(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "ðŸ“Œ Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ” Train Loss: 1.2607 | Train Acc: 66.38%\n",
      "âœ” Test Loss:  0.4881 | Test Acc:  92.00%\n",
      "\n",
      "ðŸ“Œ Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ” Train Loss: 0.3481 | Train Acc: 95.88%\n",
      "âœ” Test Loss:  0.2527 | Test Acc:  96.00%\n",
      "\n",
      "ðŸ“Œ Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ” Train Loss: 0.1969 | Train Acc: 97.75%\n",
      "âœ” Test Loss:  0.2037 | Test Acc:  96.00%\n",
      "\n",
      "ðŸ“Œ Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ” Train Loss: 0.1453 | Train Acc: 98.25%\n",
      "âœ” Test Loss:  0.1968 | Test Acc:  96.00%\n",
      "\n",
      "ðŸ“Œ Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ” Train Loss: 0.1204 | Train Acc: 98.12%\n",
      "âœ” Test Loss:  0.1712 | Test Acc:  95.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ---------------------------\n",
    "# Load Pretrained ResNet50\n",
    "# ---------------------------\n",
    "resnet = models.resnet50(pretrained=True)\n",
    "\n",
    "# Freeze all layers except final\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace FC layer for 10 classes\n",
    "num_features = resnet.fc.in_features\n",
    "resnet.fc = nn.Linear(num_features, 10)\n",
    "\n",
    "resnet = resnet.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(resnet.fc.parameters(), lr=0.001)\n",
    "\n",
    "# ---------------------------\n",
    "# Training Function\n",
    "# ---------------------------\n",
    "def train_epoch(model, loader):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    progress = tqdm(loader, desc=\"Training\", leave=False)\n",
    "\n",
    "    for images, labels in progress:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        progress.set_postfix(loss=loss.item())\n",
    "\n",
    "    acc = 100 * correct / total\n",
    "    return running_loss / len(loader), acc\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Evaluation Function\n",
    "# ---------------------------\n",
    "def eval_epoch(model, loader):\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    progress = tqdm(loader, desc=\"Evaluating\", leave=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in progress:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            progress.set_postfix(loss=loss.item())\n",
    "\n",
    "    acc = 100 * correct / total\n",
    "    return running_loss / len(loader), acc\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Train for 5 Epochs\n",
    "# ---------------------------\n",
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nðŸ“Œ Epoch {epoch+1}/{EPOCHS}\")\n",
    "\n",
    "    train_loss, train_acc = train_epoch(resnet, train_loader)\n",
    "    test_loss, test_acc = eval_epoch(resnet, test_loader)\n",
    "\n",
    "    print(f\"âœ” Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"âœ” Test Loss:  {test_loss:.4f} | Test Acc:  {test_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as cnn_animal10.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(resnet.state_dict(), \"cnn_animal10.pth\")\n",
    "print(\"Model saved as cnn_animal10.pth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f051e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "âœ” Model Loaded Successfully!\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Œ Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cane       0.94      0.85      0.89        20\n",
      "     cavallo       0.80      1.00      0.89        20\n",
      "    elefante       0.91      1.00      0.95        20\n",
      "    farfalla       1.00      0.95      0.97        20\n",
      "     gallina       1.00      1.00      1.00        20\n",
      "       gatto       1.00      1.00      1.00        20\n",
      "       mucca       1.00      0.80      0.89        20\n",
      "      pecora       0.95      1.00      0.98        20\n",
      "       ragno       1.00      0.95      0.97        20\n",
      "  scoiattolo       0.95      0.95      0.95        20\n",
      "\n",
      "    accuracy                           0.95       200\n",
      "   macro avg       0.96      0.95      0.95       200\n",
      "weighted avg       0.96      0.95      0.95       200\n",
      "\n",
      "\n",
      "ðŸ”¥ Final CNN Test Accuracy: 95.00%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ---------------------------\n",
    "# 1. Rebuild the SAME model\n",
    "# ---------------------------\n",
    "model = models.resnet50(pretrained=False)   # no pretrained this time\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, 10)      # 10 classes\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Load Saved Weights\n",
    "# ---------------------------\n",
    "model.load_state_dict(torch.load(\"cnn_animal10.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "print(\"\\nâœ” Model Loaded Successfully!\\n\")\n",
    "\n",
    "# ---------------------------\n",
    "# 3. Evaluation\n",
    "# ---------------------------\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "# ---------------------------\n",
    "# 4. Confusion Matrix\n",
    "# ---------------------------\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "classes = cnn_dataset.classes\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=classes, yticklabels=classes)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix - Animal10 CNN\")\n",
    "plt.show()\n",
    "\n",
    "# ---------------------------\n",
    "# 5. Classification Report\n",
    "# ---------------------------\n",
    "print(\"\\nðŸ“Œ Classification Report:\\n\")\n",
    "print(classification_report(all_labels, all_preds, target_names=classes))\n",
    "\n",
    "# ---------------------------\n",
    "# 6. Final Accuracy\n",
    "# ---------------------------\n",
    "acc = (all_preds == all_labels).mean() * 100\n",
    "print(f\"\\nðŸ”¥ Final CNN Test Accuracy: {acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b6c8869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as cnn_animal10.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(resnet.state_dict(), \"cnn_animal10.pth\")\n",
    "print(\"Model saved as cnn_animal10.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "75b3ccb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ” ResNet50 CNN checkpoint loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def load_resnet_cnn_model(path=\"cnn_animal10.pth\"):\n",
    "    # Create SAME ResNet50 model\n",
    "    model = models.resnet50(pretrained=True)\n",
    "\n",
    "    # Freeze layers\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Replace last layer for 10 classes (same as training)\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, 10)\n",
    "\n",
    "    # Load your weights\n",
    "    model.load_state_dict(torch.load(path, map_location=device))\n",
    "\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    print(\"âœ” ResNet50 CNN checkpoint loaded successfully.\")\n",
    "    return model\n",
    "\n",
    "cnn_model = load_resnet_cnn_model(\"cnn_animal10.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb1ad1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
